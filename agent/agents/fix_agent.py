"""
Fix Agent - Generates code fixes using LLM reasoning

NO TEMPLATES. All fixes are generated by Bedrock Claude.
If LLM fails, the agent returns an error - it does NOT fake a response.
"""
import re
import ast
import json
import logging
import boto3
from typing import Dict, Any, List
from strands import Agent, tool

from .config import DEMO_MODE, AWS_REGION, BEDROCK_MODEL_ID

logger = logging.getLogger(__name__)

# Initialize Bedrock client
bedrock_runtime = None
try:
    bedrock_runtime = boto3.client('bedrock-runtime', region_name=AWS_REGION)
    logger.info("‚úÖ Bedrock runtime client initialized for code generation")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Bedrock client init failed: {e}")

# =============================================================================
# TOOLS - Code fix generation and validation
# =============================================================================

@tool(name="generate_code_fix")
def generate_code_fix(
    error_context: str, 
    root_cause: str, 
    language: str = "javascript"
) -> str:
    """
    Generate a code fix using Bedrock Claude.
    Creates specific, applicable code changes to resolve the error.
    
    Args:
        error_context: The error message and stack trace
        root_cause: The identified root cause
        language: Programming language for the fix
    
    Returns:
        JSON with generated fix code
    """
    logger.info(f"üîß Generating code fix for {language}")
    
    prompt = f"""You are an expert software engineer. Generate a precise code fix for this error.

## CONTEXT

**Programming Language:** {language}

**Root Cause Analysis:**
{root_cause}

**Full Error (including stack trace):**
```
{error_context}
```

## YOUR TASK

Analyze the error carefully and generate a FIX that:
1. Directly addresses the ROOT CAUSE (not just the symptom)
2. Is syntactically correct for {language}
3. Can be copy-pasted and used immediately
4. Includes any necessary imports or setup

## APPROACH

1. **Read the error message carefully** - What is it actually saying?
2. **Look at the stack trace** - Where exactly does the error occur?
3. **Understand the root cause** - Why is this happening?
4. **Generate a targeted fix** - Not generic boilerplate, but THE fix for THIS error

## EXAMPLES OF GOOD vs BAD RESPONSES

### Example 1: Connection Error (ECONNREFUSED)

**Error:** `Error: connect ECONNREFUSED 127.0.0.1:5432`

‚ùå **BAD Response:**
```json
{{
  "fix_type": "null_check",
  "fixed_code": "data?.map(x => x)",
  "explanation": "Add null check"
}}
```
This is BAD because: It's a CONNECTION error, not a null reference. The fix is completely unrelated.

‚úÖ **GOOD Response:**
```json
{{
  "fix_type": "connection_handling",
  "original_pattern": "const client = new Client(); await client.connect();",
  "fixed_code": "const client = new Client({{ host: 'localhost', port: 5432, connectionTimeoutMillis: 5000 }});\\n\\nasync function connectWithRetry(maxAttempts = 3) {{\\n  for (let i = 0; i < maxAttempts; i++) {{\\n    try {{\\n      await client.connect();\\n      console.log('Connected to PostgreSQL');\\n      return;\\n    }} catch (err) {{\\n      console.error(`Connection attempt ${{i + 1}} failed:`, err.message);\\n      if (i < maxAttempts - 1) await new Promise(r => setTimeout(r, 1000 * (i + 1)));\\n    }}\\n  }}\\n  throw new Error('Failed to connect after ' + maxAttempts + ' attempts');\\n}}",
  "explanation": "PostgreSQL on port 5432 is refusing connections. This could mean: (1) PostgreSQL is not running, (2) it's running on a different port, or (3) it's not accepting connections from localhost. The fix adds retry logic with exponential backoff and explicit connection timeout.",
  "additional_changes": ["Verify PostgreSQL is running: sudo systemctl status postgresql", "Check PostgreSQL is listening: sudo netstat -tlnp | grep 5432", "Check pg_hba.conf allows local connections"]
}}
```
This is GOOD because: It correctly identifies this as a database connection issue and provides a relevant fix with retry logic.

### Example 2: Import Error

**Error:** `ModuleNotFoundError: No module named 'pandas'`

‚ùå **BAD Response:**
```json
{{
  "fix_type": "error_handling",
  "fixed_code": "try {{ import pandas }} catch (e) {{ }}",
  "explanation": "Wrap in try-catch"
}}
```
This is BAD because: The module is MISSING, not throwing an exception. You need to INSTALL it.

‚úÖ **GOOD Response:**
```json
{{
  "fix_type": "install_dependency",
  "original_pattern": "import pandas as pd",
  "fixed_code": "# First, install the missing package:\\n# pip install pandas\\n\\n# If using a virtual environment, ensure it's activated:\\n# source venv/bin/activate  # Linux/Mac\\n# venv\\\\Scripts\\\\activate   # Windows\\n\\n# Then the import will work:\\nimport pandas as pd",
  "explanation": "The 'pandas' package is not installed in the current Python environment. This is an installation issue, not a code issue.",
  "additional_changes": ["Add pandas to requirements.txt: pandas>=2.0.0", "If using poetry: poetry add pandas", "If using conda: conda install pandas"]
}}
```

## OUTPUT FORMAT

Respond with ONLY valid JSON (no markdown, no explanation outside JSON):

```json
{{
  "fix_type": "descriptive type (e.g., 'retry_logic', 'null_check', 'install_dependency', 'syntax_fix', 'type_conversion')",
  "original_pattern": "the problematic code that causes the error (if identifiable from stack trace)",
  "fixed_code": "the complete corrected code - ready to use",
  "explanation": "2-3 sentences: What's wrong, why the fix works, any caveats",
  "additional_changes": ["other recommended changes", "configuration changes", "verification steps"]
}}
```

Generate the fix now:"""

    # REQUIRE Bedrock - no templates
    if not bedrock_runtime:
        error_msg = "Fix generation failed: Bedrock client not available"
        logger.error(f"‚ùå {error_msg}")
        return json.dumps({
            "success": False,
            "error": error_msg,
            "fix_type": "error",
            "explanation": "LLM service unavailable. Cannot generate fix without AI reasoning."
        })
    
    try:
        response = bedrock_runtime.invoke_model(
            modelId=BEDROCK_MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 2000,
                "temperature": 0.1,  # Lower temperature for more consistent output
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        
        response_body = json.loads(response['body'].read())
        content = response_body.get('content', [{}])[0].get('text', '{}')
        
        try:
            start = content.find('{')
            end = content.rfind('}') + 1
            if start != -1 and end > start:
                result = json.loads(content[start:end])
                result["success"] = True
                logger.info(f"‚úÖ Generated fix: {result.get('fix_type', 'unknown')}")
                return json.dumps(result)
        except json.JSONDecodeError as je:
            logger.error(f"‚ùå Failed to parse LLM response: {je}")
            
        # LLM returned unparseable response
        return json.dumps({
            "success": False,
            "error": "Failed to parse LLM response",
            "raw_response": content[:500],
            "fix_type": "error"
        })
            
    except Exception as e:
        error_msg = f"Fix generation failed: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        return json.dumps({
            "success": False,
            "error": error_msg,
            "fix_type": "error",
            "explanation": "LLM call failed. Check Bedrock service and permissions."
        })


@tool(name="validate_syntax")
def validate_syntax(code: str, language: str) -> str:
    """
    Validate that generated code has correct syntax.
    Helps ensure fix suggestions are valid before presenting.
    
    Args:
        code: The code to validate
        language: Programming language
    
    Returns:
        JSON with validation result
    """
    logger.info(f"‚úì Validating {language} syntax")
    
    is_valid = True
    errors = []
    
    if language == "python":
        try:
            ast.parse(code)
        except SyntaxError as e:
            is_valid = False
            errors.append({
                "line": e.lineno,
                "message": e.msg,
                "text": e.text
            })
    elif language in ["javascript", "typescript"]:
        # Basic JavaScript validation (check for common issues)
        # In production, use a proper JS parser like esprima
        
        # Check balanced brackets
        brackets = {'(': ')', '[': ']', '{': '}'}
        stack = []
        for i, char in enumerate(code):
            if char in brackets:
                stack.append((char, i))
            elif char in brackets.values():
                if not stack:
                    is_valid = False
                    errors.append({"position": i, "message": f"Unmatched closing bracket: {char}"})
                else:
                    open_bracket, _ = stack.pop()
                    if brackets[open_bracket] != char:
                        is_valid = False
                        errors.append({"position": i, "message": f"Mismatched brackets: expected {brackets[open_bracket]}, got {char}"})
        
        if stack:
            is_valid = False
            for bracket, pos in stack:
                errors.append({"position": pos, "message": f"Unclosed bracket: {bracket}"})
    
    result = {
        "is_valid": is_valid,
        "language": language,
        "error_count": len(errors),
        "errors": errors[:5],  # Limit
        "message": "Syntax is valid" if is_valid else f"Found {len(errors)} syntax errors"
    }
    
    logger.info(f"‚úÖ Validation: {'valid' if is_valid else 'invalid'}")
    return json.dumps(result)


@tool(name="suggest_prevention")
def suggest_prevention(root_cause: str, language: str, error_context: str = "") -> str:
    """
    Use LLM to suggest preventive measures based on the specific error.
    
    Args:
        root_cause: Root cause analysis
        language: Programming language
        error_context: The original error for context
    
    Returns:
        JSON with prevention suggestions
    """
    logger.info(f"üõ°Ô∏è Generating prevention suggestions for {language}")
    
    if not bedrock_runtime:
        return json.dumps({
            "success": False,
            "error": "Bedrock not available for prevention suggestions",
            "suggestions": []
        })
    
    prompt = f"""Based on this error and root cause, suggest preventive measures.

Language: {language}
Root Cause: {root_cause}
Error Context: {error_context[:500] if error_context else 'Not provided'}

Provide 3-5 specific, actionable suggestions to prevent this error in the future.
Consider: linting, testing, code patterns, tooling, monitoring.

Respond with JSON:
{{
    "suggestions": [
        {{"category": "...", "suggestion": "...", "tool": "..."}}
    ]
}}"""

    try:
        response = bedrock_runtime.invoke_model(
            modelId=BEDROCK_MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 800,
                "temperature": 0.2,
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        
        response_body = json.loads(response['body'].read())
        content = response_body.get('content', [{}])[0].get('text', '{}')
        
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end > start:
            result = json.loads(content[start:end])
            result["success"] = True
            logger.info(f"‚úÖ Generated {len(result.get('suggestions', []))} prevention suggestions")
            return json.dumps(result)
            
    except Exception as e:
        logger.error(f"‚ùå Prevention suggestion failed: {e}")
    
    return json.dumps({
        "success": False,
        "error": "Failed to generate prevention suggestions",
        "suggestions": []
    })


@tool(name="generate_test_case")
def generate_test_case(fixed_code: str, error_scenario: str, language: str) -> str:
    """
    Use LLM to generate a test case specific to the fix and error.
    
    Args:
        fixed_code: The fixed code
        error_scenario: Description of what was failing
        language: Programming language
    
    Returns:
        JSON with generated test code
    """
    logger.info(f"üß™ Generating test case for {language}")
    
    if not bedrock_runtime:
        return json.dumps({
            "success": False,
            "error": "Bedrock not available for test generation",
            "test_code": ""
        })
    
    prompt = f"""Generate a test case for this fix.

Language: {language}
Error Scenario: {error_scenario}

Fixed Code:
{fixed_code[:1000] if fixed_code else 'Not provided'}

Create a test that:
1. Verifies the error case is now handled correctly
2. Verifies normal operation still works

Use the appropriate test framework for {language}.

Respond with JSON:
{{
    "test_code": "...",
    "test_framework": "...",
    "test_count": 2,
    "covers_error_case": true,
    "covers_happy_path": true
}}"""

    try:
        response = bedrock_runtime.invoke_model(
            modelId=BEDROCK_MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 1000,
                "temperature": 0.2,
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        
        response_body = json.loads(response['body'].read())
        content = response_body.get('content', [{}])[0].get('text', '{}')
        
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end > start:
            result = json.loads(content[start:end])
            result["success"] = True
            logger.info(f"‚úÖ Generated test case for {language}")
            return json.dumps(result)
            
    except Exception as e:
        logger.error(f"‚ùå Test generation failed: {e}")
    
    return json.dumps({
        "success": False,
        "error": "Failed to generate test case",
        "test_code": ""
    })


# =============================================================================
# AGENT - Strands Agent with fix tools
# =============================================================================

FIX_AGENT_PROMPT = """You are an Expert Code Fix Specialist.

## YOUR MISSION
Generate PRECISE, WORKING code fixes that directly address the root cause of errors.
Your fixes must be copy-paste ready and syntactically correct.

## QUALITY STANDARDS

### What Makes a GOOD Fix:
- Directly addresses the actual error (not a generic pattern)
- Is syntactically correct and complete
- Includes necessary imports/setup
- Has a clear explanation of WHY it fixes the issue
- Can be immediately applied

### What Makes a BAD Fix:
- Generic boilerplate that doesn't match the error
- Missing imports or incomplete code
- Fixing the wrong thing (e.g., null check for a connection error)
- Vague explanation like "handles the error"

## YOUR TOOLS
- generate_code_fix: Generate the primary fix using LLM reasoning
- validate_syntax: Verify the fix has correct syntax
- suggest_prevention: Recommend how to prevent this error in future
- generate_test_case: Create a test to verify the fix works

## YOUR WORKFLOW
1. **Analyze**: Carefully read the error message and root cause
2. **Generate**: Call generate_code_fix with full context
3. **Validate**: Call validate_syntax to ensure code is correct
4. **Prevent**: Call suggest_prevention for long-term improvements
5. **Test**: Call generate_test_case for verification

## OUTPUT REQUIREMENTS
Return a JSON object:
{
    "fix_type": "descriptive type (e.g., 'connection_retry', 'null_guard', 'import_fix')",
    "original_pattern": "the code that causes the error",
    "fixed_code": "complete, working corrected code",
    "explanation": "2-3 sentences explaining what was wrong and why this fixes it",
    "is_valid": true|false,
    "prevention": ["list of preventive measures"],
    "test_code": "test to verify the fix"
}

CRITICAL: The fix MUST match the actual error. A connection error needs connection handling, not null checks.
"""

fix_agent = Agent(
    system_prompt=FIX_AGENT_PROMPT,
    tools=[generate_code_fix, validate_syntax, suggest_prevention, generate_test_case],
)


# =============================================================================
# INTERFACE - For supervisor to call
# =============================================================================

def generate(
    error_text: str, 
    root_cause: str, 
    language: str = "javascript",
    context: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    Generate a fix for an error with full context.
    
    Args:
        error_text: The error message
        root_cause: Root cause analysis
        language: Programming language
        context: Additional context including:
            - stack_frames: List of {file, line, function}
            - external_solutions: Solutions from GitHub/SO
        
    Returns:
        Dict with fix and supporting materials
    """
    logger.info(f"üî® FixAgent: Generating fix for {language}")
    
    # Build context section for the prompt
    context_section = ""
    if context:
        stack_frames = context.get("stack_frames", [])
        external = context.get("external_solutions", {})
        
        if stack_frames:
            frames_str = "\n".join([
                f"  - {f.get('file', 'unknown')}:{f.get('line', '?')} in {f.get('function', 'unknown')}"
                for f in stack_frames[:5]
            ])
            context_section += f"\nStack Trace:\n{frames_str}\n"
        
        if external:
            if external.get("stackoverflow_answers"):
                answers = external.get("stackoverflow_answers", [])[:2]
                for ans in answers:
                    if ans.get("code_snippets"):
                        context_section += f"\nSolution from StackOverflow (score: {ans.get('score', 0)}):\n"
                        context_section += f"```\n{ans['code_snippets'][0][:500]}\n```\n"
            
            if external.get("summary", {}).get("recommended_approach"):
                context_section += f"\nRecommended approach from research:\n{external['summary']['recommended_approach']}\n"
    
    try:
        prompt = f"""Generate a fix for this error:

Error: {error_text}

Root Cause: {root_cause}

Language: {language}
{context_section}

Analyze the error and context above to generate a specific, targeted fix.
Generate the fix, validate it, suggest prevention, and create a test."""
        
        result = fix_agent(prompt)
        response_text = str(result)
        
        try:
            start = response_text.find('{')
            end = response_text.rfind('}') + 1
            if start != -1 and end > start:
                parsed = json.loads(response_text[start:end])
                parsed["success"] = True
                logger.info(f"‚úÖ FixAgent complete: {parsed.get('fix_type', 'unknown')}")
                return parsed
        except json.JSONDecodeError as je:
            logger.error(f"‚ùå Failed to parse agent response: {je}")
        
        # NO FALLBACK - return error
        return {
            "success": False,
            "error": "Failed to parse fix agent response",
            "fix_type": "error",
            "explanation": "The fix agent did not return a valid response."
        }
        
    except Exception as e:
        logger.error(f"‚ùå FixAgent error: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "fix_type": "error",
            "explanation": "Fix generation failed. Check agent configuration and LLM availability."
        }

